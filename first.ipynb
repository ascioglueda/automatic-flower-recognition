{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torch import nn, optimc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Directory Exists: True\n",
      "Valid Directory Exists: True\n",
      "Test Directory Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Veri yolları\n",
    "import os\n",
    "\n",
    "base_dir = r\"C:\\Users\\DeLL\\Desktop\\flowers\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "valid_dir = os.path.join(base_dir, \"valid\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "print(\"Train Directory Exists:\", os.path.exists(train_dir))\n",
    "print(\"Valid Directory Exists:\", os.path.exists(valid_dir))\n",
    "print(\"Test Directory Exists:\", os.path.exists(test_dir))\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "valid_dir = os.path.join(base_dir, \"valid\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# Veri dönüşümleri\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Görselleri 224x224 boyutlarına getir\n",
    "    transforms.ToTensor(),  # Tensöre dönüştür\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalleştirme\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sınıflar: ['Abutilon Çiçeği', 'Abuzambak', 'Acemi Borusu Bitkisi', 'Aconitum Fischeri', 'Afrika Papatyası', 'Ahşap Anemon Çiçeği', 'Akasma', 'Alev Çiçeği', 'Altın Otu', 'Anemon Çiçeği', 'Antoryum', 'Aslanağzı', 'Atatürk Çiçeği', 'Ateş Lalesi', 'Ay Orkidesi', 'Aynısefa Çiçeği', 'Ayyıldız Çiçeği', 'Ayçiçeği', 'Açelya', 'Balon Çiçeği', 'Bataklık Süseni', 'Begonvil', 'Bergamot', 'Beyaz Gaura Bitkisi', 'Bodrum Papatyası', 'Brovalya Çiçeği', 'California Haşhaş', 'Cattleya Orkidesi', 'Cautleya Zambak', 'Cennet Kuşu Çiçeği', 'Dağ Çiçeği', 'Deve Dikeni', 'Düğün Çiçeği', 'Ermeni Sümbülü', 'Ezan Çiçeği', 'Gazanya Çiçeği', 'Gelincik', 'Gerbera Çiçeği', 'Glayör Çiçeği', 'Guzmanya Çiçeği', 'Gül', 'Gümüş Çalısı', 'GümüşTerlik Orkidesi', 'Gündüz Sefası Çiçeği', 'Güzel Hatun Çiçeği', 'Haseki Küpesi Çiçeği', 'Hava Çiçeği', 'Havaifişek Çiçeği', 'Hercai Menekşe', 'Hint Lotusu', 'Hint Mabet Ağacı', 'Horoz İbiği Çiçeği', 'Itırşahi Çiçeği', 'Japon Gülü', 'Kadife Çiçeği', 'Kala Çiçeği', 'Kamelya Çiçeği', 'Kaplan Zambağı', 'Karahindiba', 'Karanfil', 'Kardelen Anemon Çiçeği', 'Kirpi Koni Çiçeği', 'Kral Protea', 'Kırmızı Yıldız Çiçeği', 'Kırmızı Zencefil', 'Latin Çiçeği', 'Leopar Zambağı', 'Lisyantus Çiçeği', 'Manolya Çiçeği', 'Mavi Hibiskus', 'Meksika Ayçiçeği', 'Meksika Yıldızı', 'Narin Çiçeği', 'Nergis', 'Nilüfer', 'Pamuk Çiçeği', 'Papatya', 'Peru Zambağı', 'Petunya', 'Sardunya', 'Sarı Şebboy', 'Satranç Çiçeği', 'Siam Lale', 'Sıklamen Çiçeği', 'Tesbih Çiçeği', 'Topuz Dikeni', 'Uyuz Otu', 'Yabani Enginar', 'Yüksük Otu', 'Yılan Otu', 'Yıldız Orkidesi', 'Yıldız Çiçeği', 'Çan Çiçeği', 'Çarkıfelek', 'Çin Karanfili', 'Çiğdem Çiçek', 'Çuha Çiçeği', 'Çöl Gülü', 'Çöplemecik', 'Çörek Otu Çiçeği', 'Öksürük Otu', 'İris Süsen Çiçeği']\n"
     ]
    }
   ],
   "source": [
    "# Veri setlerini yükle\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(valid_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Veri yükleyiciler\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Sınıf isimlerini çıkar\n",
    "classes = train_dataset.classes\n",
    "print(\"Sınıflar:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DeLL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DeLL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\DeLL/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:10<00:00, 4.37MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.5419, Accuracy: 62.88%\n",
      "Epoch 2/10, Loss: 0.5005, Accuracy: 86.20%\n",
      "Epoch 3/10, Loss: 0.2260, Accuracy: 94.08%\n",
      "Epoch 4/10, Loss: 0.2130, Accuracy: 93.94%\n",
      "Epoch 5/10, Loss: 0.1252, Accuracy: 96.72%\n",
      "Epoch 6/10, Loss: 0.1123, Accuracy: 96.99%\n",
      "Epoch 7/10, Loss: 0.2078, Accuracy: 93.86%\n",
      "Epoch 8/10, Loss: 0.0957, Accuracy: 97.47%\n",
      "Epoch 9/10, Loss: 0.0783, Accuracy: 97.71%\n",
      "Epoch 10/10, Loss: 0.0908, Accuracy: 97.39%\n"
     ]
    }
   ],
   "source": [
    "# Önceden eğitilmiş ResNet18 modelini yükle\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modelin son katmanını düzenle\n",
    "num_classes = len(classes)  # Bitki türü sayısı\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Cihaz ayarı (GPU kullanımı)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Kayıp fonksiyonu ve optimizasyon\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Modeli eğit\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeli Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doğrulama fonksiyonu\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Validasyon ve test doğruluğu\n",
    "valid_accuracy = evaluate(model, valid_loader)\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Kaydedilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"plant_recognition_model.pth\")\n",
    "print(\"Model kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitilen Model ile Tahmin Yapma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin Edilen Bitki Türü: Açelya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeLL\\AppData\\Local\\Temp\\ipykernel_27588\\231298520.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"plant_recognition_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image #görüntü dosyalarını işlemek için\n",
    "\n",
    "# Görüntü tahmini\n",
    "def predict_image(image_path, model, classes):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0)  # Batch boyutu ekle\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    return classes[preds.item()]\n",
    "\n",
    "# Örnek tahmin\n",
    "model.load_state_dict(torch.load(\"plant_recognition_model.pth\"))\n",
    "test_image_path = \"C:\\\\Users\\\\DeLL\\\\Desktop\\\\flowers\\\\img2.jpg\"\n",
    "predicted_class = predict_image(test_image_path, model, classes)\n",
    "print(f\"Tahmin Edilen Bitki Türü: {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
